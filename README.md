# 'SSD Framework + MobileNets Neural Network' based Deep-Learning-Human-Detector
A Deep-Learning Human Detector that works in real time and works in Simulated Envirnoments with up to 84% precision. For real world testing, the average precision is between 95-100%. Implemented in a Python and OpenCV Conda environment and can be implemented with ROS (Robotics Operating System) and Raspberry Pi, for mobile applications (drones).

This real-time detector achieves good FPS (around 15-25 in testing), accuracy and precision, while being perfectly suited for its intended application on a drone. For this model, open source pre-trained weights are available and can detect 20 classes, including humans, making the implementation in OpenCV effortless. In more detail, the model that was employed is a Caffe implementation of the original TensorFlow method seen in the original MobileNets paper, and the model’s weights were trained by Github user chuanqi305 (access at:github.com/chuanqi305/MobileNet-SSD): fine-tuned on the VOC Pascal database after initially being trained on the COCO datase, the model reached up to a 72.7% mAP, as presented above. The implementation of the model’s pre-trained weights in the Python and OpenCV environment is attached in 'human_detection_custom.py'.
